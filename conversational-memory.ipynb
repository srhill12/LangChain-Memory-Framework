{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables.\n",
    "load_dotenv()\n",
    "\n",
    "# Set the model name for our LLMs.\n",
    "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
    "# Store the API key in a variable.\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Siamese\n",
      "2. Maine Coon\n",
      "\n",
      "Poodles, Bichon Frises, and Portuguese Water Dogs are known to shed the least among the listed breeds.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model.\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=OPENAI_MODEL, temperature=0.3)\n",
    "\n",
    "# Define a query as a string.\n",
    "query = \"What are two common breeds of cats?\"\n",
    "\n",
    "# Pass the query to the invoke method, and print the result.\n",
    "result = llm.invoke(query)\n",
    "print(result.content)\n",
    "\n",
    "print()\n",
    "\n",
    "# Define a query as a string.\n",
    "query = \"Which of those shed the least?\"\n",
    "\n",
    "# Pass the query to the invoke method, and print the result.\n",
    "result = llm.invoke(query)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for conversational memory.\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: What are two common breeds of cats?\n",
      "AI:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenhill/anaconda3/envs/dev/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use RunnableWithMessageHistory: https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Two common breeds of cats are the domestic shorthair and the Persian cat. The domestic shorthair is a mixed breed cat with a short coat and a variety of colors and patterns. The Persian cat is known for its long, luxurious coat and distinctive flat face.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What are two common breeds of cats?\n",
      "AI: Two common breeds of cats are the domestic shorthair and the Persian cat. The domestic shorthair is a mixed breed cat with a short coat and a variety of colors and patterns. The Persian cat is known for its long, luxurious coat and distinctive flat face.\n",
      "Human: Which of those shed the least?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The Persian cat sheds less than the domestic shorthair because of its long, thick coat that tends to trap loose fur. However, regular grooming is still necessary to prevent matting and keep the coat healthy.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model.\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=OPENAI_MODEL, temperature=0.3)\n",
    "\n",
    "# Initialize an object for conversational memory.\n",
    "buffer = ConversationBufferMemory()\n",
    "\n",
    "# Create the chain for conversation, using a ConversationBufferMemory object.\n",
    "conversation = ConversationChain(llm=llm, verbose=True, memory=buffer)\n",
    "\n",
    "# Define a query as a string.\n",
    "query = \"What are two common breeds of cats?\"\n",
    "\n",
    "# Pass the query to the predict method and print the result.\n",
    "result = conversation.predict(input=query)\n",
    "print(result)\n",
    "\n",
    "print()\n",
    "\n",
    "# Define a query as a string.\n",
    "query = \"Which of those shed the least?\"\n",
    "\n",
    "# Pass the query to the predict method, and print the result.\n",
    "result = conversation.predict(input=query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summaries as memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for summary-based memory.\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: What are two common breeds of cats?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Two common breeds of cats are the domestic shorthair and the Persian. The domestic shorthair is a mixed breed cat with short fur, while the Persian is known for its long, luxurious coat and flat face. Both breeds are popular choices for pet owners due to their unique characteristics and personalities.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human asks the AI about two common breeds of cats. The AI responds that the domestic shorthair and the Persian are popular choices for pet owners due to their unique characteristics and personalities.\n",
      "Human: Which of those shed the least?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The domestic shorthair generally sheds less than the Persian cat. Their short coat requires minimal grooming compared to the long, thick fur of the Persian breed. However, shedding can vary between individual cats, so regular brushing and grooming are still important for both breeds.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human asks the AI about two common breeds of cats. The AI responds that the domestic shorthair and the Persian are popular choices for pet owners due to their unique characteristics and personalities. The AI also mentions that the domestic shorthair generally sheds less than the Persian cat, but regular grooming is still important for both breeds to manage shedding.\n",
      "Human: Which one tends to weigh more?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The Persian cat tends to weigh more than the domestic shorthair. Persians are known for their larger size and stockier build compared to the domestic shorthair. On average, a Persian cat can weigh between 7 to 12 pounds, while a domestic shorthair typically weighs between 8 to 12 pounds. However, it's important to note that individual cats within each breed can vary in weight depending on factors such as age, diet, and exercise level.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model for summaries.\n",
    "summary_llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY,\n",
    "                         model_name=OPENAI_MODEL,\n",
    "                         temperature=0.0)\n",
    "\n",
    "# Initialize the model for output.\n",
    "chat_llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY,\n",
    "                      model_name=OPENAI_MODEL,\n",
    "                      temperature=0.7)\n",
    "\n",
    "# Initialize an object for conversational memory.\n",
    "buffer = ConversationSummaryMemory(llm=summary_llm)\n",
    "\n",
    "# Create the chain for conversation, using the ConversationBufferMemory object.\n",
    "conversation = ConversationChain(llm=chat_llm, memory=buffer, verbose=True)\n",
    "\n",
    "# Define a query as a string.\n",
    "query = \"What are two common breeds of cats?\"\n",
    "\n",
    "# Pass the query to the predict method, and print the result.\n",
    "result = conversation.predict(input=query)\n",
    "print(result)\n",
    "\n",
    "print()\n",
    "\n",
    "# Define a query as a string.\n",
    "query = \"Which of those shed the least?\"\n",
    "\n",
    "# Pass the query to the predict method, and print the result.\n",
    "result = conversation.predict(input=query)\n",
    "print(result)\n",
    "\n",
    "print()\n",
    "\n",
    "# Define a query as a string.\n",
    "query = \"Which one tends to weigh more?\"\n",
    "\n",
    "# Pass the query to the predict method, and print the result.\n",
    "result = conversation.predict(input=query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity-based Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for entity-based memory.\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{'Godric': '', 'Maine Coon': '', 'Luna': '', 'Bombay': ''}\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Last line:\n",
      "Human: There are two cats up for adoption: Godric is a Maine Coon, and Luna is a Bombay.\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{'Godric': 'Godric is a Maine Coon.', 'Luna': 'Luna is a Bombay cat.'}\n",
      "\n",
      "Current conversation:\n",
      "Human: There are two cats up for adoption: Godric is a Maine Coon, and Luna is a Bombay.\n",
      "AI: That's great to hear that Godric and Luna are up for adoption! Maine Coons are known for their large size, friendly demeanor, and playful nature, while Bombays are known for their sleek black coat and affectionate personality. Both breeds can make wonderful companions for the right family. Have you decided which one you might be interested in adopting, or are you still considering your options?\n",
      "Last line:\n",
      "Human: Which of those cats probably has shorter fur?\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on their breed characteristics, Luna, the Bombay cat, likely has shorter fur compared to Godric, the Maine Coon. Bombays typically have a sleek, short coat, while Maine Coons have a long and thick coat. So if you're looking for a cat with shorter fur, Luna would be the better choice between the two.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{}\n",
      "\n",
      "Current conversation:\n",
      "Human: There are two cats up for adoption: Godric is a Maine Coon, and Luna is a Bombay.\n",
      "AI: That's great to hear that Godric and Luna are up for adoption! Maine Coons are known for their large size, friendly demeanor, and playful nature, while Bombays are known for their sleek black coat and affectionate personality. Both breeds can make wonderful companions for the right family. Have you decided which one you might be interested in adopting, or are you still considering your options?\n",
      "Human: Which of those cats probably has shorter fur?\n",
      "AI: Based on their breed characteristics, Luna, the Bombay cat, likely has shorter fur compared to Godric, the Maine Coon. Bombays typically have a sleek, short coat, while Maine Coons have a long and thick coat. So if you're looking for a cat with shorter fur, Luna would be the better choice between the two.\n",
      "Last line:\n",
      "Human: Which cat probably has a calmer temperament?\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on their breed characteristics, Godric, the Maine Coon, likely has a calmer temperament compared to Luna, the Bombay. Maine Coons are known for their friendly and sociable nature, as well as their gentle demeanor. Bombays, on the other hand, are affectionate but can be more playful and energetic. So if you're looking for a cat with a calmer temperament, Godric would be the better choice between the two.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model for entities.\n",
    "entity_llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY,\n",
    "                        model_name=OPENAI_MODEL,\n",
    "                        temperature=0.0)\n",
    "\n",
    "# Initialize the model for output.\n",
    "chat_llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY,\n",
    "                      model_name=OPENAI_MODEL,\n",
    "                      temperature=0.7)\n",
    "\n",
    "# Initialize an object for conversational memory.\n",
    "buffer = ConversationEntityMemory(llm=entity_llm)\n",
    "\n",
    "# Create the chain for conversation, using a ConversationBufferMemory object.\n",
    "conversation = ConversationChain(\n",
    "    llm=chat_llm, \n",
    "    memory=buffer, \n",
    "    verbose=True, \n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    ")\n",
    "\n",
    "# Define a query as a string.\n",
    "query = \"There are two cats up for adoption: Godric is a Maine Coon, and Luna is a Bombay.\"\n",
    "\n",
    "# Pass the query to the predict method.\n",
    "result = conversation.predict(input=query)\n",
    "\n",
    "# Define a query as a string.\n",
    "query = \"Which of those cats probably has shorter fur?\"\n",
    "\n",
    "# Pass the query to the predict method, and print the result.\n",
    "result = conversation.predict(input=query)\n",
    "print(result)\n",
    "\n",
    "# Define a query as a string.\n",
    "query = \"Which cat probably has a calmer temperament?\"\n",
    "\n",
    "# Pass the query to the predict method, and print the result.\n",
    "result = conversation.predict(input=query)\n",
    "print(result)\n",
    "\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
